{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406612e1",
   "metadata": {},
   "source": [
    "# Escaping the Barren Plateau\n",
    "\n",
    "**QOSF Monthly Challenge - [Jun 2025]**\n",
    "\n",
    "**Author:** Tan Jun Liang\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f0b7a",
   "metadata": {},
   "source": [
    "## üìÑ Abstract\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "Variational Quantum Algorithms (VQAs) are a leading strategy for unlocking the power of near-term quantum computers for problems in optimization, machine learning, and chemistry. VQAs work by using a classical optimizer to train the parameters of a quantum circuit, much like a classical neural network.\n",
    "\n",
    "However, as we scale up our quantum models to more qubits, we run into a devastating problem: the **Barren Plateau**. Imagine trying to find the lowest point in a vast, perfectly flat desert. If there's no slope, you don't know which way to go. For a VQA, the \"landscape\" of the optimization problem can become exponentially flat as the number of qubits increases, causing the training gradients to vanish. An optimizer with a zero-gradient is lost in the desert, and the training completely fails.\n",
    "\n",
    "This phenomenon is a critical barrier to scaling quantum machine learning. In this challenge, your mission is to witness, diagnose, and overcome the barren plateau.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1bd86",
   "metadata": {},
   "source": [
    "## üìö 1. The Theory of Barren Plateaus: A Review\n",
    "\n",
    "The practical utility of any VQA hinges on the ability of a classical optimizer to successfully train a Parameterized Quantum Circuit (PQC). The discovery of barren plateaus revealed a fundamental obstacle to this process. Research has identified several distinct mechanisms that can lead to a flat, untrainable optimization landscape.\n",
    "\n",
    "<img src=\"images/output.png\" width=\"600\">\n",
    "\n",
    "### 1.1 Depth-Induced Barren Plateaus\n",
    "\n",
    "The original work by **McClean et al. [1]** identified that deep PQCs with random parameter initializations form approximate \"2-designs.\" A 2-design is a distribution of unitary transformations that mimics the statistical properties of the full space of all possible unitaries (the Haar measure) up to the second moment. This high degree of scrambling effectively randomizes the output, causing the expectation value of any observable to concentrate exponentially around a fixed value (typically zero), leading to vanishing gradients.\n",
    "\n",
    "### 1.2 Cost Function-Induced Barren Plateaus\n",
    "\n",
    "A subsequent discovery by **Cerezo et al. [2]** showed that barren plateaus can exist even in shallow circuits if the cost function is sufficiently *global*. A global cost function involves observables that act non-trivially on many qubits (e.g., measuring the parity of all qubits, `ZZ...Z`). Due to the phenomenon of concentration of measure, the expectation values of such observables also concentrate exponentially, leading to vanishing gradients independent of circuit depth. Conversely, **local cost functions**, which measure only a few qubits, are immune to this specific mechanism.\n",
    "\n",
    "### 1.3 Noise-Induced Barren Plateaus (NIBPs)\n",
    "\n",
    "Even a VQA with a shallow circuit and a local cost function can fail if subjected to sufficient noise. As shown by **Wang et al. [3]**, the presence of global quantum noise (i.e., noise channels acting on all qubits) can itself induce a barren plateau. The noise effectively contracts the reachable state space towards the maximally mixed state, flattening the landscape and destroying the gradient, a phenomenon termed Noise-Induced Barren Plateaus (NIBPs).\n",
    "\n",
    "This notebook will empirically investigate all three phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460e681",
   "metadata": {},
   "source": [
    "## üî¨ 2. The Challenge: A Unified Experiment Runner\n",
    "\n",
    "To make this a more interesting challenge and avoid replicating code, your primary task is to complete a single, powerful `run_experiment` function. This function will be capable of testing all our hypotheses about barren plateaus by taking arguments that control the experimental conditions.\n",
    "\n",
    "### **Setup and Your Main Task**\n",
    "\n",
    "**Your Task:** Complete the `run_experiment` function below by filling in the sections marked `--- YOUR CODE HERE ---`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Setup and Your Main Task ---\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Parameters ---\n",
    "QUBIT_COUNTS = range(2, 10, 2)\n",
    "N_TRIALS = 50\n",
    "\n",
    "# --- The Correct PQC Definition (Based on the Paper) ---\n",
    "dev = qml.device('default.qubit', wires=max(QUBIT_COUNTS))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def pqc(params, observable, n_qubits, depth):\n",
    "    \"\"\"\n",
    "    A PQC that faithfully follows the recipe from McClean et al. (2018).\n",
    "    \"\"\"\n",
    "    wires = list(range(n_qubits))\n",
    "    \n",
    "    # --- Step 1: Initial, non-parameterized symmetry-breaking layer ---\n",
    "    for i in wires:\n",
    "        qml.RY(np.pi / 4, wires=i)\n",
    "    \n",
    "    # --- Step 2: Layered, parameterized ansatz ---\n",
    "    for d in range(depth):\n",
    "        # Layer of single-qubit rotations\n",
    "        for i in wires:\n",
    "            qml.Rot(*params[d, i], wires=i)\n",
    "        # Layer of entangling gates\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "            \n",
    "    return qml.expval(observable)\n",
    "\n",
    "# --- Plotting function ---\n",
    "def plot_all_variances(results, title):\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    plot_styles = {\n",
    "        'Shallow / Local': {'color': 'blue', 'label': 'Part 1: Shallow, Local Cost (Trainable)'},\n",
    "        'Deep / Local': {'color': 'red', 'label': 'Part 2: Deep, Local Cost (Depth-Induced BP)'},\n",
    "        'Shallow / Global': {'color': 'green', 'label': 'Part 3: Shallow, Global Cost (Cost-Induced BP)'}\n",
    "    }\n",
    "    \n",
    "    for key, variances in results.items():\n",
    "        style = plot_styles[key]\n",
    "        plt.plot(QUBIT_COUNTS, variances, 'o-', color=style['color'], label=style['label'])\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Number of Qubits', fontsize=14)\n",
    "    plt.ylabel('Gradient Variance (log scale)', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Setup Complete. This version is a faithful replication of the paper's method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6a82a",
   "metadata": {},
   "source": [
    "### **Running the Experiments & Visualizing the Results**\n",
    "\n",
    "**Your Task:** Once you have completed the function above, run this cell to execute all three core experiments and plot their results on a single graph for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e50187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: The Experiment Logic ---\n",
    "\n",
    "def run_experiment(cost_type, depth_rule):\n",
    "    \"\"\"\n",
    "    Runs one full, correct experiment to measure gradient variance.\n",
    "    \n",
    "    Args:\n",
    "        cost_type (str): 'local' or 'global'.\n",
    "        depth_rule (str): 'deep' (scales with n_qubits) or 'shallow'.\n",
    "    \"\"\"\n",
    "    variances = []\n",
    "    \n",
    "    for n_qubits in tqdm(QUBIT_COUNTS, desc=f\"Testing {depth_rule}/{cost_type}\"):\n",
    "        \n",
    "        # --- YOUR TASK 1: Determine circuit depth based on the rule ---\n",
    "        # If depth_rule is 'deep', depth should equal n_qubits.\n",
    "        # Otherwise, depth should be shallow_depth.\n",
    "        # --- YOUR CODE HERE ---\n",
    "        depth = 0\n",
    "\n",
    "        # --- YOUR TASK 2: Define the observable ---\n",
    "        # If cost_type is 'local', use PauliZ(0).\n",
    "        # If cost_type is 'global', use the tensor product of PauliZ on all qubits.\n",
    "        # hint: use qml.prod\n",
    "        # --- YOUR CODE HERE ---\n",
    "        observable = None\n",
    "            \n",
    "        # --- YOUR TASK 3: Create the gradient function ---\n",
    "        # Ensure the correct 'depth' variable is passed to the PQC.\n",
    "        # hint: use qml.grad and lambda function\n",
    "        # --- YOUR CODE HERE ---\n",
    "        grad_fn = None\n",
    "        \n",
    "        gradients = []\n",
    "        for _ in range(N_TRIALS):\n",
    "            # Always use wide initialization for a fair statistical sample.\n",
    "            params_shape = (depth, n_qubits, 3)\n",
    "            params = np.random.uniform(0, 2 * np.pi, size=params_shape)\n",
    "\n",
    "            grad_val = grad_fn(params)[0, 0, 0] # Grad wrt first param\n",
    "            gradients.append(grad_val)\n",
    "            \n",
    "        variances.append(np.var(gradients))\n",
    "        \n",
    "    return np.array(variances)\n",
    "\n",
    "print(\"experiment logic is ready. Proceed to the final cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Run All Tasks and See the Results ---\n",
    "\n",
    "# This dictionary holds the results for our three main hypotheses.\n",
    "results = {\n",
    "    # Task 1: Our baseline. Should be trainable (high, flat variance).\n",
    "    'Shallow / Local': \n",
    "        run_experiment(cost_type='local', depth_rule='shallow'),\n",
    "    \n",
    "    # Task 2: McClean et al. Should be a barren plateau (exponential decay).\n",
    "    'Deep / Local': \n",
    "        run_experiment(cost_type='local', depth_rule='deep'),\n",
    "        \n",
    "    # Task 3: Cerezo et al. Should be a barren plateau (exponential decay).\n",
    "    'Shallow / Global': \n",
    "        run_experiment(cost_type='global', depth_rule='shallow')\n",
    "}\n",
    "\n",
    "# --- Plot the results ---\n",
    "title = \"Demonstration: Gradient Variance vs. Qubits\"\n",
    "plot_all_variances(results, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32248ba4",
   "metadata": {},
   "source": [
    "### 3 Investigating Noise-Induced Barren Plateaus\n",
    "\n",
    "Finally, we investigate the NIBP phenomenon described by **Wang et al. [3]**. We will return to our \"solved\" setup from Task 1 (narrow init, local cost) but add a global depolarizing noise channel to our simulator.\n",
    "\n",
    "**Hypothesis:** The presence of global noise will induce a barren plateau, causing our previously successful training to fail.\n",
    "\n",
    "**Challenge:** Implement a simple noise model and show that the training fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 1: Define a noisy device and the noise strength ---\n",
    "# A small but significant probability of a depolarizing error on each qubit.\n",
    "NOISE_STRENGTH = 0.05 \n",
    "# We must use a device that can simulate noise (density matrices).\n",
    "dev_noisy = qml.device(\"default.mixed\", wires=max(QUBIT_COUNTS))\n",
    "\n",
    "\n",
    "# --- TASK 2: Define a new, noisy PQC ---\n",
    "# YOUR TASK: This QNode should be executed on the noisy device.\n",
    "# It should be identical to the pqc in Cell 1, but with an added\n",
    "# layer of depolarizing noise at the end of each loop in the ansatz.\n",
    "@qml.qnode(dev_noisy)\n",
    "def pqc_noisy(params, observable, n_qubits, depth):\n",
    "    \"\"\"\n",
    "    A PQC with a global depolarizing channel applied after each layer.\n",
    "    \"\"\"\n",
    "    wires = list(range(n_qubits))\n",
    "    \n",
    "    # Initial, non-parameterized symmetry-breaking layer\n",
    "    for i in wires:\n",
    "        qml.RY(np.pi / 4, wires=i)\n",
    "    \n",
    "    # Main ansatz loop\n",
    "    for d in range(depth):\n",
    "        # Parameterized layer\n",
    "        for i in wires:\n",
    "            qml.Rot(*params[d, i], wires=i)\n",
    "        # Entangling layer\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "            \n",
    "        # --- Add a layer of global noise here ---\n",
    "        # Add a qml.DepolarizingChannel with NOISE_STRENGTH to each qubit.\n",
    "        # --- YOUR CODE HERE ---\n",
    "            \n",
    "    return qml.expval(observable)\n",
    "\n",
    "\n",
    "# --- TASK 3: Run the NIBP experiment ---\n",
    "# We will reuse the logic, but call the new noisy PQC.\n",
    "def run_noisy_experiment(cost_type, depth_rule):\n",
    "    variances = []\n",
    "    for n_qubits in tqdm(QUBIT_COUNTS, desc=f\"Testing Noisy {depth_rule}/{cost_type}\"):\n",
    "        depth = 0\n",
    "        observable = None\n",
    "        \n",
    "        # Use the noisy PQC for this gradient calculation\n",
    "        grad_fn = None\n",
    "        \n",
    "        gradients = []\n",
    "        for _ in range(N_TRIALS):\n",
    "            params = np.random.uniform(0, 2 * np.pi, size=(depth, n_qubits, 3))\n",
    "            grad_val = grad_fn(params)[0, 0, 0]\n",
    "            gradients.append(grad_val)\n",
    "        variances.append(np.var(gradients))\n",
    "    return np.array(variances)\n",
    "\n",
    "# Run the experiment on our \"best-case\" scenario.\n",
    "variances_nibp = run_noisy_experiment(cost_type='local', depth_rule='shallow')\n",
    "\n",
    "\n",
    "# --- Plot the NIBP result against the successful baseline case from Cell 3 ---\n",
    "# Retrieve the successful baseline results for comparison\n",
    "trainable_variances = results['Shallow / Local']\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.plot(QUBIT_COUNTS, trainable_variances, 'o-', color='blue', label='Part 1: Trainable Landscape (Noiseless)')\n",
    "plt.plot(QUBIT_COUNTS, variances_nibp, 'o-', color='purple', label='Part 4: NIBP (Shallow, Local Cost, with Noise)')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.title('Demonstration: Noise-Induced Barren Plateau', fontsize=16)\n",
    "plt.xlabel('Number of Qubits', fontsize=14)\n",
    "plt.ylabel('Gradient Variance (log scale)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962f455",
   "metadata": {},
   "source": [
    "### 3.1 Bonus: Try a different quantum circuit setup to make this result better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e9e6c",
   "metadata": {},
   "source": [
    "## üöÄ 4. Bonus Challenge: Algorithmic Mitigation with ADAPT-VQE\n",
    "\n",
    "A highly effective, state-of-the-art mitigation strategy is to not use a fixed ansatz at all, but to build one iteratively. The **ADAPT-VQE** algorithm, introduced by **Grimsley et al.**, does exactly this. It avoids barren plateaus by design because it only ever adds operators that are guaranteed to have a large gradient, keeping the circuit depth to a minimum.\n",
    "\n",
    "**Algorithm:**\n",
    "1.  Define a \"pool\" of operators (e.g., all possible Pauli strings).\n",
    "2.  Start with a simple reference state (e.g., the `|0...0>` state).\n",
    "3.  **Loop:**\n",
    "    a. Calculate the gradient of the cost function with respect to each operator in the pool.\n",
    "    b. Select the operator with the largest gradient magnitude. This is the direction of steepest descent.\n",
    "    c. Add this operator to the end of the current ansatz.\n",
    "    d. Optimize all parameters in the newly extended ansatz.\n",
    "4.  Repeat until the largest gradient in the pool is below a threshold.\n",
    "\n",
    "Implementing this is a significant but rewarding challenge that demonstrates a true solution to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f98b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c7fc04",
   "metadata": {},
   "source": [
    "## üèÅ 5. Conclusion\n",
    "\n",
    "This investigation empirically confirmed the primary theoretical causes of barren plateaus in VQAs. We demonstrated that deep, randomly initialized circuits and the use of global cost functions are significant obstacles to trainability. Furthermore, we showed that even an otherwise well-behaved VQA can be rendered untrainable by the presence of global hardware noise, confirming the existence of NIBPs.\n",
    "\n",
    "Simple mitigation strategies, such as narrow parameter initialization and the use of local observables, proved effective against their corresponding barren plateau mechanisms. For a robust VQA, it is clear that a holistic approach, considering all potential pitfalls from ansatz design to cost function definition and noise resilience, is paramount. More advanced, adaptive methods like ADAPT-VQE offer a promising path forward for constructing scalable and trainable models.\n",
    "\n",
    "### Write summary\n",
    "\n",
    "In the markdown cell below, please describe your findings.\n",
    "*   Which mitigation strategy performed the best and why?\n",
    "*   Why did the global cost function fail to train, even with good initialization?\n",
    "*   What are the trade-offs for each method (e.g., implementation complexity)?\n",
    "*   Did you try the bonus challenge or any other creative ideas? If so, what were they and how did they perform?\n",
    "\n",
    "---\n",
    "\n",
    "*... Your analysis here ...*\n",
    "\n",
    "\n",
    "| Strategy                        | Implementation Complexity(Trivial/High) | Performance(Failed/Success) | Key Takeaway                                  |\n",
    "| ------------------------------- | --------------------------------------- | --------------------------- | --------------------------------------------- |\n",
    "| Random Init / Local Cost        | (write here)                            | (write here)                | (write here)                                  |\n",
    "| Narrow Init / Local Cost        | (write here)                            | (write here)                | (write here)                                  |\n",
    "| Narrow Init / Global Cost       | (write here)                            | (write here)                | (write here)                                  |\n",
    "| Layer-by-Layer Training (Bonus) | (write here)                            | (write here)                | (write here)                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58054c48",
   "metadata": {},
   "source": [
    "## üìñ 6. References\n",
    "\n",
    " Wang, S., et al. \"Noise-induced barren plateaus in variational quantum algorithms.\" *Nature Communications* 12.1 (2021): 6961.\n",
    "\n",
    " Cerezo, M., et al. \"Cost function dependent barren plateaus in shallow parametrized quantum circuits.\" *Nature Communications* 12.1 (2021): 1791.\n",
    "\n",
    " Grimsley, H. R., et al. \"An adaptive variational algorithm for exact molecular simulations on a quantum computer.\" *Nature Communications* 10.1 (2019): 3007.\n",
    "\n",
    " McClean, J. R., et al. \"Barren plateaus in quantum neural network training landscapes.\" *Nature Communications* 9.1 (2018): 4812."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit (dev)",
   "language": "python",
   "name": "qiskit-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
